<p>Once the simulation files have been extracted and their information stored in <strong>instances of the System class</strong>,
ML-LPA is ready to be trained to identify the lipid phases.</p>

<h2 id="requirements-for-the-systems">Requirements for the systems</h2>

<p>ML-LPA can be trained to predict <strong>multiple phases</strong> at the same time (# phases &gt;= 2). For each of the phases
being trained on, one instance of the System class is required.</p>

<p>Furthermore, to avoid issues and bias brought by <strong>over-representation of one phase</strong> as compared to the other, several
requirements have to be met:</p>

<ul>
  <li>
    <p>The <strong>molecule type should be the same</strong> in all instances.</p>
  </li>
  <li>
    <p>The <strong>number of atoms per molecule should be the same</strong> in all instances.</p>
  </li>
  <li>
    <p>The <strong>neighbour rank</strong>, and therefore the <strong>number of distances per molecule</strong>, <strong>should be the same</strong> in all instances.</p>

    <p class="notice--info">The neighbour rank can be edited anytime using the System class method <em>.getDistances()</em>. Please read the
  <a href="/mllpa/documentation/tutorials/system-class/2-methods/#intra-molecular-atomic-distances">corresponding section</a> for more details.</p>
  </li>
  <li>
    <p>The <strong>total number of molecules should be large enough</strong> to train on a significant population. We recommend to use
at least 500 molecules per instances for the training.</p>

    <p class="notice--info">If the instances does not have enough molecules per frame, ML-LPA should be trained on more than one frame.
  For example, if the instaces have 50 molecules, the training should be done on 10 frames at least.</p>

    <p class="notice--info">The number of frames can only be selected while loading the molecules from the simulation files with the
  <em>openSystem()</em> function. For more details, see the <a href="/mllpa/documentation/api/common/opensystem/">API</a>.</p>
  </li>
  <li>
    <p>The total number of molecules being used for the training <strong>should be the same in all instances</strong>.</p>

    <p class="notice--info">If the instances have different number of molecules per frame, the number of frames used for the training
  should be adjusted so <code class="language-plaintext highlighter-rouge"># frames x # molecules per frame</code> is constant. For example, if the instance A
  has 30 molecules and the instance B 90 molecules, the instance A should be trained on 3 times more frames
  than B.</p>
  </li>
</ul>

<h2 id="train-the-models">Train the models</h2>

<p>ML-LPA relies on a <strong>2-steps</strong> prediction system involving a total of <strong>4 different ML algorithms</strong> defined
in scikit-learn. More detailed information on the prediction system and the ML algorithms used can be found
in a <a href="/mllpa/documentation/tutorials/phase-prediction/3-ml-prediction/">later tutorial</a>.</p>

<h3 id="generate-the-model-files">Generate the model files</h3>

<p>Once all the requirements have been met, ML-LPA is ready to be trained. This is done using the function
<em>generateModel()</em>. The inputs of the function are two lists: (1) one list containing all <strong>the systems with the different phases</strong>
to be trained on, and (2) one list with their <strong>respective labels</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">mllpa</span>

<span class="c1"># We import one set of simulation files per phase
</span><span class="n">gel_system</span> <span class="o">=</span> <span class="n">mllpa</span><span class="p">.</span><span class="n">openSystem</span><span class="p">(</span><span class="s">'gel.gro'</span><span class="p">,</span> <span class="s">'gel.tpr'</span><span class="p">,</span> <span class="s">'DPPC'</span><span class="p">)</span>
<span class="n">fluid_system</span> <span class="o">=</span> <span class="n">mllpa</span><span class="p">.</span><span class="n">openSystem</span><span class="p">(</span><span class="s">'fluid.gro'</span><span class="p">,</span> <span class="s">'fluid.tpr'</span><span class="p">,</span> <span class="s">'DPPC'</span><span class="p">)</span>

<span class="c1"># Train the models and saved them in a file
</span><span class="n">mllpa</span><span class="p">.</span><span class="n">generateModel</span><span class="p">([</span><span class="n">gel_system</span><span class="p">,</span> <span class="n">fluid_system</span><span class="p">],</span> <span class="n">phases</span><span class="o">=</span><span class="p">[</span><span class="s">'gel'</span><span class="p">,</span> <span class="s">'fluid'</span><span class="p">],</span> <span class="n">file_path</span><span class="o">=</span><span class="s">'new_model.lpm'</span><span class="p">)</span>
</code></pre></div></div>

<p class="notice--info">In this example, the coordinates and structure files of the gel and fluid phases
are respectively called <em>gel.gro</em> and <em>gel.tpr</em>, and <em>fluid.gro</em> and <em>fluid.tpr</em>.
We use the <em>openSystem()</em> function to load the information from
the simulation files. Check the <a href="/mllpa/documentation/tutorials/loading-files/1-simulation-files/">related tutorial</a> for more details.</p>

<p>Once the training has been completed, the models are stored in a <strong>.lpm</strong> (<ins>L</ins>ipid <ins>P</ins>hase <ins>M</ins>odel) file at the given location.
This file can be used anytime to predict the phases in a simulation of unknown composition. More details on the
.lpm files are given in the <a href="/mllpa/documentation/tutorials/outputs/1-model-file/">corresponding tutorial</a>.</p>

<h3 id="extract-directly-the-models-in-variables">Extract directly the models in variables</h3>

<p>For many reasons, one can decide to <strong>not save the models in a file</strong>, and just extract them directly in variables to use them
straight. This can be done by disabling the <em>save_model=</em> keyword-argument:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models</span> <span class="o">=</span> <span class="n">mllpa</span><span class="p">.</span><span class="n">generateModel</span><span class="p">([</span><span class="n">gel_system</span><span class="p">,</span> <span class="n">fluid_system</span><span class="p">],</span> <span class="n">phases</span><span class="o">=</span><span class="p">[</span><span class="s">'gel'</span><span class="p">,</span> <span class="s">'fluid'</span><span class="p">],</span> <span class="n">save_model</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>The models are returned in a dictionary of instances of <strong>specific scikit-learn classes</strong>.</p>

<p>You can find the description of all the keyword-arguments of the <em>generateModel()</em> function in the <a href="/mllpa/documentation/api/common/generatemodel/">API</a>.</p>

<h2 id="assessing-reproducibility-and-scoring">Assessing reproducibility and scoring</h2>

<p>One issue that can arise while training ML models with a set of data is that the size of the dataset will
<strong>never be large enough</strong> to correspond exactly to all the <strong>population of possible configurations</strong> for each phase.
As a consequence, we are bound to train our models on a <strong>sample</strong> that we hope large enough to prevent any training bias.</p>

<p>In order to check whether the sample of <strong>N molecules</strong> is a <em>good enough representation</em> of the population, ML-LPA will proceed
by <strong>resampling</strong> the input data and generate <strong>K times</strong> 3 different sub-samples of respective sizes <strong>j N</strong>, <strong>j N</strong> and <strong>(1-j) N</strong>,
where <strong>K</strong> and <strong>j</strong> can be set by the user, and <strong>j</strong> a float between 0 and 0.33.</p>

<center><img src="/mllpa/assets/images/tutorials/training.png" width="500" height="500" /></center>
<center><sub>Flowchart of the logic used to train the ML models</sub></center>
<p><br /></p>

<p>The sample of size (1-j)N and one of the samples of size jN will be used to train the 2-steps prediction system, while the
other sample of size jN is used to assess the accuracy of the system and of each algorithm. The final score and reproducibility are
calculated from the <strong>K repetitions of the resampling and training</strong>.</p>

<h2 id="what-is-next">What is next?</h2>

<ul>
  <li>
    <p>Now that you know how to generate a model in ML-LPA, the next obvious step would be to
use it to <a href="/mllpa/documentation/tutorials/phase-prediction/3-ml-prediction/">predict the phases</a> in an unknown system.</p>
  </li>
  <li>
    <p>You can also check how to <a href="/mllpa/documentation/tutorials/outputs/1-model-file/">read the scores in the .lpm files</a>
or <a href="/mllpa/documentation/tutorials/phase-prediction/2-rank-optimisation/">optimise the neighbour rank</a>.</p>
  </li>
</ul>

<h2 id="check-the-api">Check the API</h2>

<p>The following elements have been used in this tutorial:</p>

<ul>
  <li><a href="/mllpa/documentation/tutorials/phase-prediction/2-model-file/">generateModel()</a></li>
</ul>
